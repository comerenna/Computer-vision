!pip install tf-nightly

!pip install --upgrade tensorflow

import os
import random
import glob
import gc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_class_weight

import tensorflow as tf
from tensorflow.keras.utils import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import load_img
from keras.preprocessing.image import ImageDataGenerator
from keras.models import *
from keras.layers import *
from keras.callbacks import *
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input

BATCH_SIZE = 32

SEED = 666
tf.random.set_seed(SEED)
np.random.seed(SEED)
os.environ["PYTHONHASHSEED"] = str(SEED)                      
random.seed(666)

TRAIN_PATH = "data-task1/train"
VAL_PATH = "data-task1/val"
TEST_PATH = "data-task1/test"

print(f"Normal X-Rays From Validation Set: {len(os.listdir(VAL_PATH + '/NORMAL'))} ")

print(f"Pneumonia X-Rays From Validation Set: {len(os.listdir(VAL_PATH + '/PNEUMONIA'))} ")

train_normal = pd.DataFrame({"path": os.listdir(TRAIN_PATH + "/NORMAL"), "label": "NORMAL"})
train_normal["path"] = train_normal["path"].apply(lambda x: TRAIN_PATH + "/NORMAL/" + x)
train_pneumonia = pd.DataFrame({"path": os.listdir(TRAIN_PATH + "/PNEUMONIA"), "label": "PNEUMONIA"})
train_pneumonia["path"] = train_pneumonia["path"].apply(lambda x: TRAIN_PATH + "/PNEUMONIA/" + x)

train_df = pd.concat([train_normal, train_pneumonia])

val_normal = pd.DataFrame({"path": os.listdir(VAL_PATH + "/NORMAL"), "label": "NORMAL"})
val_normal["path"] = val_normal["path"].apply(lambda x: VAL_PATH + "/NORMAL/" + x)
val_pneumonia = pd.DataFrame({"path": os.listdir(VAL_PATH + "/PNEUMONIA"), "label": "PNEUMONIA"})
val_pneumonia["path"] = val_pneumonia["path"].apply(lambda x: VAL_PATH + "/PNEUMONIA/" + x)

val_df = pd.concat([val_normal, val_pneumonia])

train_data, val_data = train_test_split(train_df, 
                                        test_size = 0.1, 
                                        random_state = SEED, 
                                        stratify = train_df["label"], 
                                        shuffle = True)

val_data = pd.concat([val_df, val_data])

print(f"Training set size after re-splitting training data: {len(train_data)}")
print(f"Validation set size after re-splitting training data: {len(val_data)}")

fig, ax = plt.subplots(figsize = (6, 6), facecolor = "#e5e5e5")
ax.set_facecolor("#e5e5e5")

sns.countplot(data = train_data, x = "label", ax = ax, color = "#101820")

ax.set_title("Countplot for Train Labels")

sns.despine()
plt.show()


fig = plt.figure(1, figsize = (16, 16))
fig.suptitle("NORMAL X-Rays")

for i in range(36):
    
    ind = random.randint(0, len(train_data.query("label == 'NORMAL'")))

    plt.subplot(6, 6, i + 1)
    image = load_img(train_data.query("label == 'NORMAL'").reset_index()["path"][ind])
    plt.imshow(image)
    plt.title(train_data.query("label == 'NORMAL'").reset_index()["label"][ind])
    plt.axis("off")
    
plt.tight_layout()
plt.show()

fig = plt.figure(1, figsize = (16, 16))
fig.suptitle("Pneumonia X-Rays")

for i in range(36):
    
    ind = random.randint(0, len(train_data.query("label == 'PNEUMONIA'")))

    plt.subplot(6, 6, i + 1)
    image = load_img(train_data.query("label == 'PNEUMONIA'").reset_index()["path"][ind])
    plt.imshow(image)
    plt.title(train_data.query("label == 'PNEUMONIA'").reset_index()["label"][ind])
    plt.axis("off")
    
plt.tight_layout()
plt.show()

datagen = ImageDataGenerator(
    brightness_range = (0.2, 1), 
    zoom_range = 0.2,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    horizontal_flip = True,
    rescale = 1./255
)

sample_df = train_data.sample(1)

sample_generator = datagen.flow_from_dataframe(
    dataframe = sample_df,
    x_col = "path",
    y_col = "label",
    class_mode = "categorical",
    target_size = (150, 150),
    seed = 666
)

plt.figure(figsize = (14, 8))

for i in range(50):
    
    plt.subplot(5, 10, i + 1)
    
    for X, y in sample_generator:

        plt.imshow(X[0])
        plt.axis("off")
        break
        
plt.tight_layout()
plt.show()

train_datagen = ImageDataGenerator(
    brightness_range = (0.2, 1), 
    zoom_range = 0.2,
    width_shift_range = 0.1,
    height_shift_range = 0.1,
    horizontal_flip = True,
    preprocessing_function = preprocess_input
)

val_datagen = ImageDataGenerator(
    preprocessing_function = preprocess_input
)

test_datagen = ImageDataGenerator(
    preprocessing_function = preprocess_input
)

train_generator = train_datagen.flow_from_dataframe(
    dataframe = train_data,
    x_col = "path",
    y_col = "label",
    target_size = (150, 150),
    class_mode = "categorical",
    batch_size = BATCH_SIZE,
    shuffle = True,
    seed = SEED
)

val_generator = val_datagen.flow_from_dataframe(
    dataframe = val_data,
    x_col = "path",
    y_col = "label",
    target_size = (150, 150),
    class_mode = "categorical",
    batch_size = BATCH_SIZE,
    shuffle = True,
    seed = SEED
)

test_generator = test_datagen.flow_from_directory(
    directory = TEST_PATH,
    target_size = (150, 150),
    class_mode = "categorical",
    batch_size = BATCH_SIZE,
    shuffle = False,
    seed = SEED
)

class_weights = compute_class_weight("balanced", classes = np.unique(train_data.label), y = train_data.label)

class_weights = {0: class_weights[0], 1: class_weights[1]}

base_model = DenseNet121(include_top = False, weights = "imagenet", input_shape = (150, 150, 3))

    
def dense121_pretrained():
    
    model = Sequential(
        [
            base_model,
            Flatten(),
            Dense(128, activation = "relu"),
            Dropout(0.25),
            Dense(2, activation = "softmax")
        ]
    )
    
    return model

tf.keras.backend.clear_session()

model = dense121_pretrained()

model.summary()

reduce_lr = ReduceLROnPlateau(
    monitor = "val_accuracy", 
    patience = 2,
    verbose = 1, 
    factor = 0.3, 
    min_lr = 0.000000001,
    cooldown = 1
)

early_stopping = EarlyStopping(
    monitor = "val_accuracy",
    patience = 10,
    verbose = 1,
    mode = "max",
)

checkpoint = ModelCheckpoint(
    monitor = "val_accuracy",
    filepath = "pneumonia_densenet121_.{epoch:02d}-{val_accuracy:.6f}.hdf5",
    verbose = 1,
    save_best_only = True, 
    save_weights_only = True
)

model.compile(loss = "categorical_crossentropy", optimizer = "adam", metrics = "accuracy")

history = model.fit(
    train_generator,
    epochs = 10, 
    batch_size = BATCH_SIZE,
    validation_data = val_generator,
    validation_steps = val_data.shape[0] // BATCH_SIZE,
    steps_per_epoch = train_data.shape[0] // BATCH_SIZE,
    callbacks = [reduce_lr, early_stopping, checkpoint],
    class_weight = class_weights
)


Learning Curves

fig, axes = plt.subplots(1, 2, figsize = (12, 4))

sns.lineplot(x = range(len(history.history["loss"])), y = history.history["loss"], ax = axes[0], label = "Training Loss")
sns.lineplot(x = range(len(history.history["loss"])), y = history.history["val_loss"], ax = axes[0], label = "Validation Loss")

sns.lineplot(x = range(len(history.history["accuracy"])), y = history.history["accuracy"], ax = axes[1], label = "Training Accuracy")
sns.lineplot(x = range(len(history.history["accuracy"])), y = history.history["val_accuracy"], ax = axes[1], label = "Validation Accuracy")
axes[0].set_title("Loss"); axes[1].set_title("Accuracy")

sns.despine()
plt.show()


Validation Set Performance

val_generator = val_datagen.flow_from_dataframe(
    dataframe = val_data,
    x_col = "path",
    y_col = "label",
    target_size = (150, 150),
    class_mode = "categorical",
    batch_size = BATCH_SIZE,
    shuffle = False,
    seed = SEED
)


val_pred = model.predict(val_generator, steps = np.ceil(val_data.shape[0] / BATCH_SIZE))
val_data.loc[:, "val_pred"] = np.argmax(val_pred, axis = 1)

labels = dict((v, k) for k, v in val_generator.class_indices.items())

val_data.loc[:, "val_pred"] = val_data.loc[:, "val_pred"].map(labels)

fig, ax = plt.subplots(figsize = (9, 6))

cm = confusion_matrix(val_data["label"], val_data["val_pred"])

disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ["Normal", "Pneunomia"])
disp.plot(cmap = plt.cm.Blues, ax = ax)

ax.set_title("Validation Set")
plt.show()


print(classification_report(val_data["label"], val_data["val_pred"]))

Test Set Performance

test_normal = pd.DataFrame({"path": os.listdir(TEST_PATH + "/NORMAL"), "label": "NORMAL"})
test_normal["path"] = test_normal["path"].apply(lambda x: TEST_PATH + "/NORMAL/" + x)
test_pneumonia = pd.DataFrame({"path": os.listdir(TEST_PATH + "/PNEUMONIA"), "label": "PNEUMONIA"})
test_pneumonia["path"] = test_pneumonia["path"].apply(lambda x: TEST_PATH + "/PNEUMONIA/" + x)

test_df = pd.concat([test_normal, test_pneumonia])

test_generator = test_datagen.flow_from_dataframe(
    dataframe = test_df,
    x_col = "path",
    y_col = "label",
    target_size = (150, 150),
    class_mode = "categorical",
    batch_size = 1,
    shuffle = False,
    seed = SEED
)

test_pred = model.predict(test_generator)
test_df.loc[:, "test_pred"] = np.argmax(test_pred, axis = 1)

labels = dict((v, k) for k, v in test_generator.class_indices.items())

test_df.loc[:, "test_pred"] = test_df.loc[:, "test_pred"].map(labels)

fig, ax = plt.subplots(figsize = (9, 6))

cm = confusion_matrix(test_df["label"], test_df["test_pred"])

disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ["Normal", "Pneunomia"])
disp.plot(cmap = plt.cm.Blues, ax = ax)

ax.set_title("Test Set")
plt.show()

print(classification_report(test_df["label"], test_df["test_pred"]))